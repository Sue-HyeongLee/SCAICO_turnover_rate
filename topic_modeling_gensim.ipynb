{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "# Gensim\n",
    "from gensim.corpora.dictionary import Dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Categories\n",
    "'''\n",
    "bank_financial_business_review\n",
    "construction_review\n",
    "distribution_trade_transport_reviews\n",
    "education_review\n",
    "manufacture_chemistry_review\n",
    "media_design_reviews\n",
    "organization_association_reviews\n",
    "medical_medicine_welfare_reviews\n",
    "service_reviews\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "IMPORT DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('/Users/myeongseop.kim/Desktop/SCAISCO/csv files/medical_medicine_welfare_reviews.csv')\n",
    "# 결측치 제거\n",
    "df = df.dropna()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # only for IT data\n",
    "# it1 = pd.read_csv('/Users/myeongseop.kim/Desktop/SCAISCO/csv files/it_web_communication_reviews_1_100.csv')\n",
    "# it2 = pd.read_csv('/Users/myeongseop.kim/Desktop/SCAISCO/csv files/it_web_communication_reviews_101_200.csv')\n",
    "# it3 = pd.read_csv('/Users/myeongseop.kim/Desktop/SCAISCO/csv files/it_web_communication_reviews_201_300.csv')\n",
    "# it4 = pd.read_csv('/Users/myeongseop.kim/Desktop/SCAISCO/csv files/it_web_communication_reviews_300_end.csv')\n",
    "\n",
    "# df= pd.concat([it1,it2,it3,it4],axis=0)\n",
    "# df.index= [i for i in range(563)]\n",
    "# # 결측치 제거\n",
    "# df = df.dropna()\n",
    "# adv = df['adv'] # Advantage review\n",
    "# dadv = df['dadv'] # Disadvantage review\n",
    "# df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TOKENIZING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Word Count\n",
    "from konlpy.tag import Okt\n",
    "\n",
    "t = Okt()\n",
    "\n",
    "def my_tokenizer(doc):\n",
    "    return [\n",
    "        token\n",
    "        for token, pos in t.pos(doc)\n",
    "        if pos == 'Noun' and len(token)>1\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_adv = [my_tokenizer(text) for text in df.adv]\n",
    "text_dadv = [my_tokenizer(text) for text in df.dadv]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary_adv = Dictionary(text_adv)\n",
    "dictionary_dadv = Dictionary(text_dadv)\n",
    "print('#Number of initial unique words in adv_documents:',len(dictionary_adv))\n",
    "print('#Number of initial unique words in dadv_documents:',len(dictionary_dadv))\n",
    "\n",
    "dictionary_adv.filter_extremes(keep_n = 2000, no_below = 10, no_above = 0.5)\n",
    "dictionary_dadv.filter_extremes(keep_n = 2000, no_below = 10, no_above = 0.5)\n",
    "print(\"#Number of unique words after removing rae and common words:\", len(dictionary_adv))\n",
    "print(\"#Number of unique words after removing rae and common words:\", len(dictionary_dadv))\n",
    "\n",
    "corpus_adv = [dictionary_adv.doc2bow(text) for text in text_adv]\n",
    "corpus_dadv = [dictionary_dadv.doc2bow(text) for text in text_dadv]\n",
    "print('#Number of unique tokens: %d' % len(dictionary_adv))\n",
    "print('#Number of documents: %d' % len(corpus_adv))\n",
    "\n",
    "print('#Number of unique tokens: %d' % len(dictionary_dadv))\n",
    "print('#Number of documents: %d' % len(corpus_dadv))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LDA MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import LdaModel\n",
    "\n",
    "num_topics_adv = 3\n",
    "passes = 5\n",
    "model_adv = LdaModel(corpus = corpus_adv, id2word = dictionary_adv,passes = passes, num_topics = num_topics_adv,random_state = 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_topics_dadv = 3\n",
    "model_dadv = LdaModel(corpus = corpus_dadv, id2word = dictionary_dadv,passes = passes, num_topics = num_topics_dadv,random_state = 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('ADV')\n",
    "print(model_adv.print_topics(num_words=10))\n",
    "print('\\n DADV')\n",
    "print(model_dadv.print_topics(num_words=10))\n",
    "# print('#topic distribution of the first document:',model.get_document_topics(corpus)[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TOPIC MODELING COMPARISON(based on # topics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # topic_modeling csv file\n",
    "# num_topic_list = [8, 11, 15]\n",
    "# save = {}\n",
    "# for i in num_topic_list:\n",
    "#     model = LdaModel(corpus = corpus, id2word = dictionary,passes = passes, num_topics = i,random_state = 7)\n",
    "#     save[i] = model.print_topics(num_words=10)\n",
    "# topic_csv = pd.DataFrame.from_dict(save, orient='index')\n",
    "# topic_csv.to_csv(\"it_topic_selection.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TOPIC MODELING OUTPUT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_df_adv = pd.DataFrame({'cmp':df.cmp})\n",
    "for col in range(num_topics_adv):\n",
    "    tmp = str(col)\n",
    "    output_df_adv[tmp] = float(0)\n",
    "output_df_adv.index = [i for i in range(len(output_df_adv))]\n",
    "output_df_adv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_df_dadv = pd.DataFrame({'cmp':df.cmp})\n",
    "for col in range(num_topics_dadv):\n",
    "    tmp = str(col)\n",
    "    output_df_dadv[tmp] = float(0)\n",
    "output_df_dadv.index = [i for i in range(len(output_df_dadv))]\n",
    "output_df_dadv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, dt in enumerate(model_adv.get_document_topics(corpus_adv)):\n",
    "    for val in dt:\n",
    "\n",
    "        idx = str(val[0])\n",
    "        pt = val[1]\n",
    "\n",
    "        output_df_adv.at[i,idx] = pt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, dt in enumerate(model_dadv.get_document_topics(corpus_dadv)):\n",
    "    for val in dt:\n",
    "\n",
    "        idx = str(val[0])\n",
    "        pt = val[1]\n",
    "\n",
    "        output_df_dadv.at[i,idx] = pt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to csv file\n",
    "# output_df.to_csv('construction_topic_modeling.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import CoherenceModel\n",
    "\n",
    "cm_adv = CoherenceModel(model= model_adv, corpus= corpus_adv, coherence= 'u_mass')\n",
    "cm_dadv = CoherenceModel(model= model_dadv, corpus= corpus_dadv, coherence= 'u_mass')\n",
    "\n",
    "coherence_adv = cm_adv.get_coherence()\n",
    "coherence_dadv = cm_dadv.get_coherence()\n",
    "\n",
    "print(coherence_adv)\n",
    "print(coherence_dadv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_coherence(corpus, dictionary, start = 6, end = 15):\n",
    "    iter_num = []\n",
    "    per_value = []\n",
    "    coh_value = []\n",
    "\n",
    "    for i in range(start, end+1):\n",
    "        model = LdaModel(corpus = corpus, id2word = dictionary, chunksize=1000, num_topics = i,random_state = 7)\n",
    "        iter_num.append(i)\n",
    "        pv = model.log_perplexity(corpus)\n",
    "        per_value.append(pv)\n",
    "\n",
    "        cm = CoherenceModel(model=model, corpus=corpus, coherence='u_mass')\n",
    "        cv = cm.get_coherence()\n",
    "        coh_value.append(cv)\n",
    "        print(f'num_topics: {i}, perplexity: {pv:0.3f}, coherence: {cv:0.3f}')\n",
    "    \n",
    "    plt.plot(iter_num, per_value, 'g-')\n",
    "    plt.xlabel(\"num_topics\")\n",
    "    plt.ylabel(\"perplexity\")\n",
    "    plt.show()\n",
    "\n",
    "    plt.plot(iter_num, coh_value, 'r--')\n",
    "    plt.xlabel(\"num_topics\")\n",
    "    plt.ylabel(\"coherence\")\n",
    "    plt.show()\n",
    "# 5, 14\n",
    "show_coherence(corpus_adv, dictionary_adv, start = 3, end = 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_coherence(corpus_dadv, dictionary_dadv, start = 3, end = 30)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "textmining",
   "language": "python",
   "name": "textmining"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
