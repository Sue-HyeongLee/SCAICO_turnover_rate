{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "# Gensim\n",
    "from gensim.corpora.dictionary import Dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nbank_financial_business_review\\nconstruction_review\\ndistribution_trade_transport_reviews\\neducation_review\\nmanufacture_chemistry_review\\nmedia_design_reviews\\norganization_association_reviews\\nmedical_medicine_welfare_reviews\\nservice_reviews\\n'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Categories\n",
    "'''\n",
    "bank_financial_business_review\n",
    "construction_review\n",
    "distribution_trade_transport_reviews\n",
    "education_review\n",
    "manufacture_chemistry_review\n",
    "media_design_reviews\n",
    "organization_association_reviews\n",
    "medical_medicine_welfare_reviews\n",
    "service_reviews\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "IMPORT DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>cmp</th>\n",
       "      <th>adv</th>\n",
       "      <th>dadv</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>(주)에스씨케이컴퍼니</td>\n",
       "      <td>휴게시간, 주휴수당 등 법적인 것을 모두 보장받을 수 있다 유동적인 적은 시간 근무...</td>\n",
       "      <td>일하는 시간 동안은 눈코뜰새 없이 일해야함. 핸드폰도 못보고 바쁠때는 화장실도 못감...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>한국맥도날드(유)</td>\n",
       "      <td>스케줄을 일주일 단위로 신청 할 수 있어서 일정 조정이 편하다. 지문으로 출퇴근 시...</td>\n",
       "      <td>피크 타임의 인원을 충원해야 하기 때문에 원하지 않는 시간대에 추가 근무 요청이 들...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>롯데리아 (매장)</td>\n",
       "      <td>식사를 챙겨준다.신입직원 교육이 길고 배려 잘 해준다. 아르바이트를 체계적으로 배울...</td>\n",
       "      <td>식사가 햄버거뿐이다.최저시급 챙겨준다.휴게시간에 쉴 공간이 없다. 바쁜 시간에는 매...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>(주)트랜스코스모스코리아</td>\n",
       "      <td>도서가 많아서 책읽기 좋고 휴게공간 식사공간이 있어서 중식시간이 편하기 휴식할 수 ...</td>\n",
       "      <td>업무특성상 휴식시간이 제공되지 않아서 화장실만 겨우 다녀온다 휴게시간이 보장되었음 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>(주)유베이스</td>\n",
       "      <td>6시 되면 칼퇴근 가능함빨간날은 다 쉼 임시공휴일도 다 쉼 전화 대응 업무라 처음에...</td>\n",
       "      <td>월급이 박봉이고 발전 가능성이 없음기업마다 근무난이도가 다름헬 인 곳은 진짜 힘들어...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0            cmp  \\\n",
       "0           0    (주)에스씨케이컴퍼니   \n",
       "1           1      한국맥도날드(유)   \n",
       "2           2      롯데리아 (매장)   \n",
       "3           3  (주)트랜스코스모스코리아   \n",
       "4           4        (주)유베이스   \n",
       "\n",
       "                                                 adv  \\\n",
       "0  휴게시간, 주휴수당 등 법적인 것을 모두 보장받을 수 있다 유동적인 적은 시간 근무...   \n",
       "1  스케줄을 일주일 단위로 신청 할 수 있어서 일정 조정이 편하다. 지문으로 출퇴근 시...   \n",
       "2  식사를 챙겨준다.신입직원 교육이 길고 배려 잘 해준다. 아르바이트를 체계적으로 배울...   \n",
       "3  도서가 많아서 책읽기 좋고 휴게공간 식사공간이 있어서 중식시간이 편하기 휴식할 수 ...   \n",
       "4  6시 되면 칼퇴근 가능함빨간날은 다 쉼 임시공휴일도 다 쉼 전화 대응 업무라 처음에...   \n",
       "\n",
       "                                                dadv  \n",
       "0  일하는 시간 동안은 눈코뜰새 없이 일해야함. 핸드폰도 못보고 바쁠때는 화장실도 못감...  \n",
       "1  피크 타임의 인원을 충원해야 하기 때문에 원하지 않는 시간대에 추가 근무 요청이 들...  \n",
       "2  식사가 햄버거뿐이다.최저시급 챙겨준다.휴게시간에 쉴 공간이 없다. 바쁜 시간에는 매...  \n",
       "3  업무특성상 휴식시간이 제공되지 않아서 화장실만 겨우 다녀온다 휴게시간이 보장되었음 ...  \n",
       "4  월급이 박봉이고 발전 가능성이 없음기업마다 근무난이도가 다름헬 인 곳은 진짜 힘들어...  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('/Users/myeongseop.kim/Desktop/SCAISCO/csv files/service_reviews.csv')\n",
    "# 결측치 제거\n",
    "df = df.dropna()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # only for It data\n",
    "# it1 = pd.read_csv('/Users/myeongseop.kim/Desktop/SCAISCO/csv files/it_web_communication_reviews_1_100.csv')\n",
    "# it2 = pd.read_csv('/Users/myeongseop.kim/Desktop/SCAISCO/csv files/it_web_communication_reviews_101_200.csv')\n",
    "# it3 = pd.read_csv('/Users/myeongseop.kim/Desktop/SCAISCO/csv files/it_web_communication_reviews_201_300.csv')\n",
    "# it4 = pd.read_csv('/Users/myeongseop.kim/Desktop/SCAISCO/csv files/it_web_communication_reviews_300_end.csv')\n",
    "\n",
    "# df= pd.concat([it1,it2,it3,it4],axis=0)\n",
    "# df.index= [i for i in range(563)]\n",
    "# # 결측치 제거\n",
    "# df = df.dropna()\n",
    "# adv = df['adv'] # Advantage review\n",
    "# dadv = df['dadv'] # Disadvantage review\n",
    "# df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TOKENIZING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Word Count\n",
    "from konlpy.tag import Okt\n",
    "\n",
    "t = Okt()\n",
    "\n",
    "def my_tokenizer(doc):\n",
    "    return [\n",
    "        token\n",
    "        for token, pos in t.pos(doc)\n",
    "        if pos in ['Noun','Verb','Adjective'] and len(token)>1\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_adv = [my_tokenizer(text) for text in df.adv]\n",
    "text_dadv = [my_tokenizer(text) for text in df.dadv]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Number of initial unique words in adv_documents: 13191\n",
      "#Number of initial unique words in dadv_documents: 21562\n",
      "#Number of unique words after removing rae and common words: 1510\n",
      "#Number of unique words after removing rae and common words: 2000\n",
      "#Number of unique tokens: 1510\n",
      "#Number of documents: 238\n",
      "#Number of unique tokens: 2000\n"
     ]
    }
   ],
   "source": [
    "dictionary_adv = Dictionary(text_adv)\n",
    "dictionary_dadv = Dictionary(text_dadv)\n",
    "print('#Number of initial unique words in adv_documents:',len(dictionary_adv))\n",
    "print('#Number of initial unique words in dadv_documents:',len(dictionary_dadv))\n",
    "\n",
    "dictionary_adv.filter_extremes(keep_n = 2000, no_below = 10, no_above = 0.5)\n",
    "dictionary_dadv.filter_extremes(keep_n = 2000, no_below = 10, no_above = 0.5)\n",
    "print(\"#Number of unique words after removing rae and common words:\", len(dictionary_adv))\n",
    "print(\"#Number of unique words after removing rae and common words:\", len(dictionary_dadv))\n",
    "\n",
    "corpus_adv = [dictionary_adv.doc2bow(text) for text in text_adv]\n",
    "corpus_dadv = [dictionary_dadv.doc2bow(text) for text in text_dadv]\n",
    "print('#Number of unique tokens: %d' % len(dictionary_adv))\n",
    "print('#Number of documents: %d' % len(corpus_adv))\n",
    "\n",
    "print('#Number of unique tokens: %d' % len(dictionary_dadv))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Number of documents: 238\n"
     ]
    }
   ],
   "source": [
    "print('#Number of documents: %d' % len(corpus_dadv))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LDA MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import LdaModel\n",
    "\n",
    "num_topics_adv = 7\n",
    "passes = 5\n",
    "model_adv = LdaModel(corpus = corpus_adv, id2word = dictionary_adv,passes = passes, num_topics = num_topics_adv,random_state = 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_topics_dadv = 8\n",
    "model_dadv = LdaModel(corpus = corpus_dadv, id2word = dictionary_dadv,passes = passes, num_topics = num_topics_dadv,random_state = 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ADV\n",
      "[(0, '0.013*\"금요일\" + 0.008*\"할인\" + 0.008*\"동료\" + 0.008*\"매월\" + 0.007*\"간식\" + 0.007*\"점심\" + 0.006*\"출근\" + 0.006*\"기숙사\" + 0.005*\"사내\" + 0.005*\"제도\"'), (1, '0.007*\"파견\" + 0.007*\"교육\" + 0.005*\"체계\" + 0.005*\"음료\" + 0.005*\"부서\" + 0.005*\"수당\" + 0.005*\"강도\" + 0.005*\"커피\" + 0.005*\"따라\" + 0.005*\"입사\"'), (2, '0.011*\"수당\" + 0.008*\"매장\" + 0.006*\"스케줄\" + 0.006*\"체계\" + 0.006*\"교육\" + 0.005*\"지급\" + 0.005*\"따라\" + 0.005*\"안정\" + 0.005*\"대한\" + 0.005*\"챙겨\"'), (3, '0.033*\"할인\" + 0.015*\"대기업\" + 0.010*\"열사\" + 0.010*\"혜택\" + 0.010*\"계열\" + 0.008*\"호텔\" + 0.008*\"사업\" + 0.007*\"수당\" + 0.007*\"스케줄\" + 0.006*\"복리\"'), (4, '0.014*\"대기업\" + 0.009*\"삼성\" + 0.008*\"포인트\" + 0.008*\"부서\" + 0.006*\"위치\" + 0.005*\"나쁘지\" + 0.005*\"수당\" + 0.005*\"부바\" + 0.005*\"재택근무\" + 0.004*\"사업\"'), (5, '0.012*\"카페\" + 0.010*\"사내\" + 0.009*\"구내식당\" + 0.009*\"지급\" + 0.009*\"차량\" + 0.007*\"점심\" + 0.007*\"건물\" + 0.006*\"사옥\" + 0.006*\"없다\" + 0.005*\"출근\"'), (6, '0.009*\"점심\" + 0.008*\"업계\" + 0.007*\"무료\" + 0.007*\"저녁\" + 0.007*\"사내\" + 0.007*\"커피\" + 0.006*\"동료\" + 0.006*\"식사\" + 0.006*\"젊은\" + 0.006*\"식당\"')]\n",
      "\n",
      " DADV\n",
      "[(0, '0.007*\"파견\" + 0.006*\"계약\" + 0.005*\"관리자\" + 0.005*\"군대\" + 0.004*\"업체\" + 0.004*\"관리\" + 0.004*\"출근\" + 0.004*\"최저\" + 0.004*\"같은\" + 0.004*\"진짜\"'), (1, '0.015*\"매장\" + 0.006*\"스케줄\" + 0.006*\"인턴\" + 0.005*\"손님\" + 0.005*\"알바\" + 0.005*\"관리\" + 0.005*\"관리자\" + 0.004*\"시급\" + 0.004*\"힘들다\" + 0.004*\"매니저\"'), (2, '0.006*\"영진\" + 0.005*\"리더\" + 0.005*\"사업\" + 0.005*\"인사\" + 0.005*\"대표\" + 0.004*\"조직\" + 0.004*\"소통\" + 0.004*\"능력\" + 0.004*\"경영\" + 0.004*\"성장\"'), (3, '0.005*\"지역\" + 0.004*\"위치\" + 0.004*\"있어서\" + 0.004*\"인사\" + 0.004*\"시험\" + 0.004*\"무량\" + 0.004*\"작업\" + 0.004*\"출근\" + 0.004*\"기숙사\" + 0.004*\"하는데\"'), (4, '0.013*\"매장\" + 0.008*\"지점\" + 0.007*\"본사\" + 0.006*\"출근\" + 0.006*\"고객\" + 0.005*\"현장\" + 0.004*\"관리\" + 0.004*\"스트레스\" + 0.004*\"교육\" + 0.004*\"진짜\"'), (5, '0.027*\"매장\" + 0.017*\"스케줄\" + 0.011*\"이벤트\" + 0.008*\"진급\" + 0.007*\"노동\" + 0.007*\"현장\" + 0.006*\"프로모션\" + 0.005*\"바이\" + 0.005*\"공부\" + 0.005*\"고객\"'), (6, '0.014*\"고객\" + 0.008*\"영업\" + 0.007*\"스트레스\" + 0.007*\"교육\" + 0.006*\"관리자\" + 0.006*\"실적\" + 0.005*\"압박\" + 0.005*\"상담\" + 0.004*\"정말\" + 0.004*\"센터\"'), (7, '0.007*\"진급\" + 0.007*\"계약\" + 0.006*\"사업\" + 0.005*\"영업\" + 0.005*\"현장\" + 0.004*\"본사\" + 0.004*\"인상\" + 0.004*\"평가\" + 0.004*\"대기업\" + 0.004*\"낮음\"')]\n"
     ]
    }
   ],
   "source": [
    "print('ADV')\n",
    "print(model_adv.print_topics(num_words=10))\n",
    "print('\\n DADV')\n",
    "print(model_dadv.print_topics(num_words=10))\n",
    "# print('#topic distribution of the first document:',model.get_document_topics(corpus)[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TOPIC MODELING COMPARISON(based on # topics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # topic_modeling csv file\n",
    "# num_topic_list_adv = [4,7,11]\n",
    "# num_topic_list_dadv = [4,8,12]\n",
    "\n",
    "# save_adv = {}\n",
    "# save_dadv = {}\n",
    "# for i in num_topic_list_adv:\n",
    "#     model = LdaModel(corpus = corpus_adv, id2word = dictionary_adv,passes = passes, num_topics = i,random_state = 7)\n",
    "#     save_adv[i] = model.print_topics(num_words=10)\n",
    "\n",
    "# for i in num_topic_list_dadv:\n",
    "#     model = LdaModel(corpus = corpus_dadv, id2word = dictionary_dadv,passes = passes, num_topics = i,random_state = 7)\n",
    "#     save_dadv[i] = model.print_topics(num_words=10)\n",
    "\n",
    "# topic_adv_csv = pd.DataFrame.from_dict(save_adv, orient='index')\n",
    "# topic_adv_csv.to_csv(\"service_adv_topic_selection.csv\")\n",
    "\n",
    "# topic_dadv_csv = pd.DataFrame.from_dict(save_dadv, orient='index')\n",
    "# topic_dadv_csv.to_csv(\"service_dadv_topic_selection.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TOPIC MODELING OUTPUT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_df_adv = pd.DataFrame({'cmp':df.cmp})\n",
    "for col in range(num_topics_adv):\n",
    "    tmp = str(col)\n",
    "    output_df_adv[tmp] = float(0)\n",
    "output_df_adv.index = [i for i in range(len(output_df_adv))]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_df_dadv = pd.DataFrame({'cmp':df.cmp})\n",
    "for col in range(num_topics_dadv):\n",
    "    tmp = str(col)\n",
    "    output_df_dadv[tmp] = float(0)\n",
    "output_df_dadv.index = [i for i in range(len(output_df_dadv))]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, dt in enumerate(model_adv.get_document_topics(corpus_adv)):\n",
    "    for val in dt:\n",
    "\n",
    "        idx = str(val[0])\n",
    "        pt = val[1]\n",
    "\n",
    "        output_df_adv.at[i,idx] = pt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, dt in enumerate(model_dadv.get_document_topics(corpus_dadv)):\n",
    "    for val in dt:\n",
    "\n",
    "        idx = str(val[0])\n",
    "        pt = val[1]\n",
    "\n",
    "        output_df_dadv.at[i,idx] = pt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to csv file\n",
    "output_df_adv.to_csv('service_adv_topic_modeling.csv')\n",
    "output_df_dadv.to_csv('service_dadv_topic_modeling.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.7848813756923683\n",
      "-0.721894931283888\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import CoherenceModel\n",
    "\n",
    "cm_adv = CoherenceModel(model= model_adv, corpus= corpus_adv, coherence= 'u_mass')\n",
    "cm_dadv = CoherenceModel(model= model_dadv, corpus= corpus_dadv, coherence= 'u_mass')\n",
    "\n",
    "coherence_adv = cm_adv.get_coherence()\n",
    "coherence_dadv = cm_dadv.get_coherence()\n",
    "\n",
    "print(coherence_adv)\n",
    "print(coherence_dadv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_topics: 3, perplexity: -7.009, coherence: -0.700\n",
      "num_topics: 4, perplexity: -7.055, coherence: -0.681\n",
      "num_topics: 5, perplexity: -7.092, coherence: -0.708\n",
      "num_topics: 6, perplexity: -7.132, coherence: -0.697\n",
      "num_topics: 7, perplexity: -7.177, coherence: -0.698\n",
      "num_topics: 8, perplexity: -7.215, coherence: -0.702\n",
      "num_topics: 9, perplexity: -7.256, coherence: -0.718\n",
      "num_topics: 10, perplexity: -7.302, coherence: -0.715\n",
      "num_topics: 11, perplexity: -7.347, coherence: -0.689\n",
      "num_topics: 12, perplexity: -7.390, coherence: -0.725\n",
      "num_topics: 13, perplexity: -7.437, coherence: -0.690\n",
      "num_topics: 14, perplexity: -7.485, coherence: -0.707\n",
      "num_topics: 15, perplexity: -7.527, coherence: -0.712\n",
      "num_topics: 16, perplexity: -7.571, coherence: -0.694\n",
      "num_topics: 17, perplexity: -7.607, coherence: -0.686\n",
      "num_topics: 18, perplexity: -7.658, coherence: -0.695\n",
      "num_topics: 19, perplexity: -7.706, coherence: -0.677\n",
      "num_topics: 20, perplexity: -7.741, coherence: -0.694\n",
      "num_topics: 21, perplexity: -7.786, coherence: -0.697\n",
      "num_topics: 22, perplexity: -7.833, coherence: -0.704\n",
      "num_topics: 23, perplexity: -7.883, coherence: -0.698\n"
     ]
    }
   ],
   "source": [
    "def show_coherence(corpus, dictionary, start = 6, end = 15):\n",
    "    iter_num = []\n",
    "    per_value = []\n",
    "    coh_value = []\n",
    "\n",
    "    for i in range(start, end+1):\n",
    "        model = LdaModel(corpus = corpus, id2word = dictionary, chunksize=1000, num_topics = i,random_state = 7)\n",
    "        iter_num.append(i)\n",
    "        pv = model.log_perplexity(corpus)\n",
    "        per_value.append(pv)\n",
    "\n",
    "        cm = CoherenceModel(model=model, corpus=corpus, coherence='u_mass')\n",
    "        cv = cm.get_coherence()\n",
    "        coh_value.append(cv)\n",
    "        print(f'num_topics: {i}, perplexity: {pv:0.3f}, coherence: {cv:0.3f}')\n",
    "    \n",
    "    plt.plot(iter_num, per_value, 'g-')\n",
    "    plt.xlabel(\"num_topics\")\n",
    "    plt.ylabel(\"perplexity\")\n",
    "    plt.show()\n",
    "\n",
    "    plt.plot(iter_num, coh_value, 'r--')\n",
    "    plt.xlabel(\"num_topics\")\n",
    "    plt.ylabel(\"coherence\")\n",
    "    plt.show()\n",
    "# 5, 14\n",
    "show_coherence(corpus_adv, dictionary_adv, start = 3, end = 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_topics: 3, perplexity: -7.397, coherence: -0.692\n",
      "num_topics: 4, perplexity: -7.452, coherence: -0.653\n",
      "num_topics: 5, perplexity: -7.512, coherence: -0.656\n",
      "num_topics: 6, perplexity: -7.567, coherence: -0.653\n",
      "num_topics: 7, perplexity: -7.626, coherence: -0.646\n",
      "num_topics: 8, perplexity: -7.684, coherence: -0.657\n",
      "num_topics: 9, perplexity: -7.745, coherence: -0.644\n",
      "num_topics: 10, perplexity: -7.802, coherence: -0.654\n",
      "num_topics: 11, perplexity: -7.861, coherence: -0.647\n",
      "num_topics: 12, perplexity: -7.915, coherence: -0.657\n",
      "num_topics: 13, perplexity: -7.978, coherence: -0.662\n",
      "num_topics: 14, perplexity: -8.037, coherence: -0.648\n",
      "num_topics: 15, perplexity: -8.093, coherence: -0.657\n",
      "num_topics: 16, perplexity: -8.153, coherence: -0.648\n",
      "num_topics: 17, perplexity: -8.203, coherence: -0.661\n",
      "num_topics: 18, perplexity: -8.269, coherence: -0.655\n",
      "num_topics: 19, perplexity: -8.331, coherence: -0.659\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/myeongseop.kim/competition-by-AI/topic_modeling_gensim.ipynb 셀 25\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/myeongseop.kim/competition-by-AI/topic_modeling_gensim.ipynb#X33sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m show_coherence(corpus_dadv, dictionary_dadv, start \u001b[39m=\u001b[39;49m \u001b[39m3\u001b[39;49m, end \u001b[39m=\u001b[39;49m \u001b[39m30\u001b[39;49m)\n",
      "\u001b[1;32m/Users/myeongseop.kim/competition-by-AI/topic_modeling_gensim.ipynb 셀 25\u001b[0m line \u001b[0;36m7\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/myeongseop.kim/competition-by-AI/topic_modeling_gensim.ipynb#X33sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m coh_value \u001b[39m=\u001b[39m []\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/myeongseop.kim/competition-by-AI/topic_modeling_gensim.ipynb#X33sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(start, end\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m):\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/myeongseop.kim/competition-by-AI/topic_modeling_gensim.ipynb#X33sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m     model \u001b[39m=\u001b[39m LdaModel(corpus \u001b[39m=\u001b[39;49m corpus, id2word \u001b[39m=\u001b[39;49m dictionary, chunksize\u001b[39m=\u001b[39;49m\u001b[39m1000\u001b[39;49m, num_topics \u001b[39m=\u001b[39;49m i,random_state \u001b[39m=\u001b[39;49m \u001b[39m7\u001b[39;49m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/myeongseop.kim/competition-by-AI/topic_modeling_gensim.ipynb#X33sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m     iter_num\u001b[39m.\u001b[39mappend(i)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/myeongseop.kim/competition-by-AI/topic_modeling_gensim.ipynb#X33sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m     pv \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mlog_perplexity(corpus)\n",
      "File \u001b[0;32m~/miniconda3/envs/textmining/lib/python3.8/site-packages/gensim/models/ldamodel.py:521\u001b[0m, in \u001b[0;36mLdaModel.__init__\u001b[0;34m(self, corpus, num_topics, id2word, distributed, chunksize, passes, update_every, alpha, eta, decay, offset, eval_every, iterations, gamma_threshold, minimum_probability, random_state, ns_conf, minimum_phi_value, per_word_topics, callbacks, dtype)\u001b[0m\n\u001b[1;32m    519\u001b[0m use_numpy \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdispatcher \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    520\u001b[0m start \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n\u001b[0;32m--> 521\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mupdate(corpus, chunks_as_numpy\u001b[39m=\u001b[39;49muse_numpy)\n\u001b[1;32m    522\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39madd_lifecycle_event(\n\u001b[1;32m    523\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mcreated\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m    524\u001b[0m     msg\u001b[39m=\u001b[39m\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mtrained \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m in \u001b[39m\u001b[39m{\u001b[39;00mtime\u001b[39m.\u001b[39mtime()\u001b[39m \u001b[39m\u001b[39m-\u001b[39m\u001b[39m \u001b[39mstart\u001b[39m:\u001b[39;00m\u001b[39m.2f\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39ms\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m    525\u001b[0m )\n",
      "File \u001b[0;32m~/miniconda3/envs/textmining/lib/python3.8/site-packages/gensim/models/ldamodel.py:991\u001b[0m, in \u001b[0;36mLdaModel.update\u001b[0;34m(self, corpus, chunksize, decay, offset, passes, update_every, eval_every, iterations, gamma_threshold, chunks_as_numpy)\u001b[0m\n\u001b[1;32m    988\u001b[0m reallen \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(chunk)  \u001b[39m# keep track of how many documents we've processed so far\u001b[39;00m\n\u001b[1;32m    990\u001b[0m \u001b[39mif\u001b[39;00m eval_every \u001b[39mand\u001b[39;00m ((reallen \u001b[39m==\u001b[39m lencorpus) \u001b[39mor\u001b[39;00m ((chunk_no \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m) \u001b[39m%\u001b[39m (eval_every \u001b[39m*\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnumworkers) \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m)):\n\u001b[0;32m--> 991\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlog_perplexity(chunk, total_docs\u001b[39m=\u001b[39;49mlencorpus)\n\u001b[1;32m    993\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdispatcher:\n\u001b[1;32m    994\u001b[0m     \u001b[39m# add the chunk to dispatcher's job queue, so workers can munch on it\u001b[39;00m\n\u001b[1;32m    995\u001b[0m     logger\u001b[39m.\u001b[39minfo(\n\u001b[1;32m    996\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mPROGRESS: pass \u001b[39m\u001b[39m%i\u001b[39;00m\u001b[39m, dispatching documents up to #\u001b[39m\u001b[39m%i\u001b[39;00m\u001b[39m/\u001b[39m\u001b[39m%i\u001b[39;00m\u001b[39m\"\u001b[39m,\n\u001b[1;32m    997\u001b[0m         pass_, chunk_no \u001b[39m*\u001b[39m chunksize \u001b[39m+\u001b[39m \u001b[39mlen\u001b[39m(chunk), lencorpus\n\u001b[1;32m    998\u001b[0m     )\n",
      "File \u001b[0;32m~/miniconda3/envs/textmining/lib/python3.8/site-packages/gensim/models/ldamodel.py:847\u001b[0m, in \u001b[0;36mLdaModel.log_perplexity\u001b[0;34m(self, chunk, total_docs)\u001b[0m\n\u001b[1;32m    845\u001b[0m corpus_words \u001b[39m=\u001b[39m \u001b[39msum\u001b[39m(cnt \u001b[39mfor\u001b[39;00m document \u001b[39min\u001b[39;00m chunk \u001b[39mfor\u001b[39;00m _, cnt \u001b[39min\u001b[39;00m document)\n\u001b[1;32m    846\u001b[0m subsample_ratio \u001b[39m=\u001b[39m \u001b[39m1.0\u001b[39m \u001b[39m*\u001b[39m total_docs \u001b[39m/\u001b[39m \u001b[39mlen\u001b[39m(chunk)\n\u001b[0;32m--> 847\u001b[0m perwordbound \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbound(chunk, subsample_ratio\u001b[39m=\u001b[39;49msubsample_ratio) \u001b[39m/\u001b[39m (subsample_ratio \u001b[39m*\u001b[39m corpus_words)\n\u001b[1;32m    848\u001b[0m logger\u001b[39m.\u001b[39minfo(\n\u001b[1;32m    849\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m%.3f\u001b[39;00m\u001b[39m per-word bound, \u001b[39m\u001b[39m%.1f\u001b[39;00m\u001b[39m perplexity estimate based on a held-out corpus of \u001b[39m\u001b[39m%i\u001b[39;00m\u001b[39m documents with \u001b[39m\u001b[39m%i\u001b[39;00m\u001b[39m words\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m    850\u001b[0m     perwordbound, np\u001b[39m.\u001b[39mexp2(\u001b[39m-\u001b[39mperwordbound), \u001b[39mlen\u001b[39m(chunk), corpus_words\n\u001b[1;32m    851\u001b[0m )\n\u001b[1;32m    852\u001b[0m \u001b[39mreturn\u001b[39;00m perwordbound\n",
      "File \u001b[0;32m~/miniconda3/envs/textmining/lib/python3.8/site-packages/gensim/models/ldamodel.py:1113\u001b[0m, in \u001b[0;36mLdaModel.bound\u001b[0;34m(self, corpus, gamma, subsample_ratio)\u001b[0m\n\u001b[1;32m   1111\u001b[0m     logger\u001b[39m.\u001b[39mdebug(\u001b[39m\"\u001b[39m\u001b[39mbound: at document #\u001b[39m\u001b[39m%i\u001b[39;00m\u001b[39m\"\u001b[39m, d)\n\u001b[1;32m   1112\u001b[0m \u001b[39mif\u001b[39;00m gamma \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m-> 1113\u001b[0m     gammad, _ \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49minference([doc])\n\u001b[1;32m   1114\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1115\u001b[0m     gammad \u001b[39m=\u001b[39m gamma[d]\n",
      "File \u001b[0;32m~/miniconda3/envs/textmining/lib/python3.8/site-packages/gensim/models/ldamodel.py:719\u001b[0m, in \u001b[0;36mLdaModel.inference\u001b[0;34m(self, chunk, collect_sstats)\u001b[0m\n\u001b[1;32m    715\u001b[0m lastgamma \u001b[39m=\u001b[39m gammad\n\u001b[1;32m    716\u001b[0m \u001b[39m# We represent phi implicitly to save memory and time.\u001b[39;00m\n\u001b[1;32m    717\u001b[0m \u001b[39m# Substituting the value of the optimal phi back into\u001b[39;00m\n\u001b[1;32m    718\u001b[0m \u001b[39m# the update for gamma gives this update. Cf. Lee&Seung 2001.\u001b[39;00m\n\u001b[0;32m--> 719\u001b[0m gammad \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39malpha \u001b[39m+\u001b[39m expElogthetad \u001b[39m*\u001b[39m np\u001b[39m.\u001b[39;49mdot(cts \u001b[39m/\u001b[39;49m phinorm, expElogbetad\u001b[39m.\u001b[39;49mT)\n\u001b[1;32m    720\u001b[0m Elogthetad \u001b[39m=\u001b[39m dirichlet_expectation(gammad)\n\u001b[1;32m    721\u001b[0m expElogthetad \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mexp(Elogthetad)\n",
      "File \u001b[0;32m<__array_function__ internals>:200\u001b[0m, in \u001b[0;36mdot\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "show_coherence(corpus_dadv, dictionary_dadv, start = 3, end = 30)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "textmining",
   "language": "python",
   "name": "textmining"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
