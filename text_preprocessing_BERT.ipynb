{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "IMPORT DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('bow_df.csv')\n",
    "# 결측치 제거\n",
    "df = df.dropna()\n",
    "\n",
    "company_name = df.company_name\n",
    "company_name.to_csv(\"company_name.csv\")\n",
    "other_var = df.drop(['company_name','adv','dadv','Unnamed: 0'],axis=1)\n",
    "other_var.to_csv(\"other_var.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "불용어 처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def clean_str(text):\n",
    "    pattern = '([a-zA-Z0-9_.+-]+@[a-zA-Z0-9-]+\\.[a-zA-Z0-9-.]+)' # E-mail제거\n",
    "    text = re.sub(pattern=pattern, repl=' ', string=text)\n",
    "    pattern = '(http|ftp|https)://(?:[-\\w.]|(?:%[\\da-fA-F]{2}))+' # URL제거\n",
    "    text = re.sub(pattern=pattern, repl=' ', string=text)\n",
    "    pattern = '([ㄱ-ㅎㅏ-ㅣ]+)'  # 한글 자음, 모음 제거\n",
    "    text = re.sub(pattern=pattern, repl=' ', string=text)\n",
    "    pattern = '<[^>]*>'         # HTML 태그 제거\n",
    "    text = re.sub(pattern=pattern, repl=' ', string=text)\n",
    "    pattern = '[^\\w\\s\\n]'         # 특수기호제거\n",
    "    text = re.sub(pattern=pattern, repl=' ', string=text)\n",
    "    text = re.sub('[-=+,#/\\?:^$.@*\\\"※~&%ㆍ!』\\\\‘|\\(\\)\\[\\]\\<\\>`\\'…》]',' ', string=text)\n",
    "    text = re.sub('\\n', '.', string=text)\n",
    "    return text "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>company_name</th>\n",
       "      <th>adv</th>\n",
       "      <th>dadv</th>\n",
       "      <th>average_salary</th>\n",
       "      <th>total_sale</th>\n",
       "      <th>turn_over_rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>국민건강보험공단</td>\n",
       "      <td>휴직 종류가 다양하지 못하나 임신출산관련해서는 잘 정리된듯하다  분위기는 지사마다 ...</td>\n",
       "      <td>악성민원 진상민원을 매일 매일 마주해야한다  개편때마다 퇴사자 생기는거 보면 말다함...</td>\n",
       "      <td>6441</td>\n",
       "      <td>75400.0</td>\n",
       "      <td>0.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>근로복지공단</td>\n",
       "      <td>탄력근무  복지포인트 등 직원들의 복지 계약직도 해당  1  재택근무를 쓸 수 있다...</td>\n",
       "      <td>위탁집행형 기관 치고 급여가 적음  정규직들의 최대 불만 그래서 건보 연금 등으로 ...</td>\n",
       "      <td>5817</td>\n",
       "      <td>9406.2</td>\n",
       "      <td>0.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>농협은행</td>\n",
       "      <td>업무 강도에 비해 높은 연봉  워라밸  정년보장  젊은 분위기 등 장점이 많은 회사...</td>\n",
       "      <td>다수 보수적인 문화가 여전히 잔재하고 있음  어르신들도 많은 회사 성격좋은 윗 상급...</td>\n",
       "      <td>6182</td>\n",
       "      <td>13100.0</td>\n",
       "      <td>0.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>현대카드</td>\n",
       "      <td>일단 오피스 환경이 쾌적한것은 장점대기업만의 성과급이나 복지의 혜택등이 좋다생각보다...</td>\n",
       "      <td>꼰대문화 부서에따라 존재   굽신굽신 매일 퇴근은 정시에 포기 할일 다하면 다른업무...</td>\n",
       "      <td>8737</td>\n",
       "      <td>2300.0</td>\n",
       "      <td>0.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>중소기업은행</td>\n",
       "      <td>5일 연차 사용가능  지바지 있을 수 있지만 훌륭한 선배들이 많음  지바지 사바사지...</td>\n",
       "      <td>느린 전산  사람 상대하는 직업이다보니 사람에 대한 스트레스가 많음 서비스직이다보니...</td>\n",
       "      <td>10065</td>\n",
       "      <td>14800.0</td>\n",
       "      <td>0.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2498</th>\n",
       "      <td>212</td>\n",
       "      <td>유끼커뮤니케이션</td>\n",
       "      <td>연차 자유롭게 사용 가능함다양한 업무를 진행해볼 수 있는 곳 퇴근 시간이 칼 같이 ...</td>\n",
       "      <td>복지 제도의 부족함 느낌타이트한 업무 데드라인이 있을 때가 많음 사무실이 비교적 좁...</td>\n",
       "      <td>4417</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2499</th>\n",
       "      <td>213</td>\n",
       "      <td>투어이천</td>\n",
       "      <td>기업의 장점으로는 꼰대 문화는 거의 없고 팀바이 팀이라서 연차가 자유롭게 이용 가능...</td>\n",
       "      <td>단점은 너무나 많습니다  일단 회사인데 체계가 제대로 잡혀있지 않아서 일하기가 너무...</td>\n",
       "      <td>1314</td>\n",
       "      <td>108.9</td>\n",
       "      <td>1.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2500</th>\n",
       "      <td>214</td>\n",
       "      <td>휴먼코아</td>\n",
       "      <td>팀보단 본인만 잘하면 별 문제없습니다  통근버스 식비 지원 쉬는시간 많습니다  연차...</td>\n",
       "      <td>단순노동이라 힘들고 체력적으로 많이 힘듭니다  화장실 가는게 쫌 눈치보일정도로 바쁘...</td>\n",
       "      <td>3062</td>\n",
       "      <td>430.1</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2501</th>\n",
       "      <td>215</td>\n",
       "      <td>에이치엔씨네트워크</td>\n",
       "      <td>휴가 5개줌연차 돈으로 줌화장실 비데있음커피 차 있음일못해도 돈준다  연차 눈치안봐...</td>\n",
       "      <td>너무많아서 못쓰겠다 일하는 사람만 하고 안하는 사람은 안한다안하는 사람 루팡 개많다...</td>\n",
       "      <td>3038</td>\n",
       "      <td>336.9</td>\n",
       "      <td>0.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2502</th>\n",
       "      <td>216</td>\n",
       "      <td>현대엔지비</td>\n",
       "      <td>성장 기회 많고  책임급 급여는 그룹사에서 높은 편  자율출퇴근 어느 정도 지켜지고...</td>\n",
       "      <td>단점이 많지 않음  좋은 회사임  현대차 갑이어서 담당자에 따라 리스크가 있고 야근...</td>\n",
       "      <td>5898</td>\n",
       "      <td>633.4</td>\n",
       "      <td>0.33</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2503 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0 company_name  \\\n",
       "0              0     국민건강보험공단   \n",
       "1              1       근로복지공단   \n",
       "2              3         농협은행   \n",
       "3              4         현대카드   \n",
       "4              5       중소기업은행   \n",
       "...          ...          ...   \n",
       "2498         212     유끼커뮤니케이션   \n",
       "2499         213         투어이천   \n",
       "2500         214         휴먼코아   \n",
       "2501         215    에이치엔씨네트워크   \n",
       "2502         216        현대엔지비   \n",
       "\n",
       "                                                    adv  \\\n",
       "0     휴직 종류가 다양하지 못하나 임신출산관련해서는 잘 정리된듯하다  분위기는 지사마다 ...   \n",
       "1     탄력근무  복지포인트 등 직원들의 복지 계약직도 해당  1  재택근무를 쓸 수 있다...   \n",
       "2     업무 강도에 비해 높은 연봉  워라밸  정년보장  젊은 분위기 등 장점이 많은 회사...   \n",
       "3     일단 오피스 환경이 쾌적한것은 장점대기업만의 성과급이나 복지의 혜택등이 좋다생각보다...   \n",
       "4     5일 연차 사용가능  지바지 있을 수 있지만 훌륭한 선배들이 많음  지바지 사바사지...   \n",
       "...                                                 ...   \n",
       "2498  연차 자유롭게 사용 가능함다양한 업무를 진행해볼 수 있는 곳 퇴근 시간이 칼 같이 ...   \n",
       "2499  기업의 장점으로는 꼰대 문화는 거의 없고 팀바이 팀이라서 연차가 자유롭게 이용 가능...   \n",
       "2500  팀보단 본인만 잘하면 별 문제없습니다  통근버스 식비 지원 쉬는시간 많습니다  연차...   \n",
       "2501  휴가 5개줌연차 돈으로 줌화장실 비데있음커피 차 있음일못해도 돈준다  연차 눈치안봐...   \n",
       "2502  성장 기회 많고  책임급 급여는 그룹사에서 높은 편  자율출퇴근 어느 정도 지켜지고...   \n",
       "\n",
       "                                                   dadv average_salary  \\\n",
       "0     악성민원 진상민원을 매일 매일 마주해야한다  개편때마다 퇴사자 생기는거 보면 말다함...           6441   \n",
       "1     위탁집행형 기관 치고 급여가 적음  정규직들의 최대 불만 그래서 건보 연금 등으로 ...           5817   \n",
       "2     다수 보수적인 문화가 여전히 잔재하고 있음  어르신들도 많은 회사 성격좋은 윗 상급...           6182   \n",
       "3     꼰대문화 부서에따라 존재   굽신굽신 매일 퇴근은 정시에 포기 할일 다하면 다른업무...           8737   \n",
       "4     느린 전산  사람 상대하는 직업이다보니 사람에 대한 스트레스가 많음 서비스직이다보니...          10065   \n",
       "...                                                 ...            ...   \n",
       "2498  복지 제도의 부족함 느낌타이트한 업무 데드라인이 있을 때가 많음 사무실이 비교적 좁...           4417   \n",
       "2499  단점은 너무나 많습니다  일단 회사인데 체계가 제대로 잡혀있지 않아서 일하기가 너무...           1314   \n",
       "2500  단순노동이라 힘들고 체력적으로 많이 힘듭니다  화장실 가는게 쫌 눈치보일정도로 바쁘...           3062   \n",
       "2501  너무많아서 못쓰겠다 일하는 사람만 하고 안하는 사람은 안한다안하는 사람 루팡 개많다...           3038   \n",
       "2502  단점이 많지 않음  좋은 회사임  현대차 갑이어서 담당자에 따라 리스크가 있고 야근...           5898   \n",
       "\n",
       "     total_sale  turn_over_rate  \n",
       "0       75400.0            0.20  \n",
       "1        9406.2            0.13  \n",
       "2       13100.0            0.15  \n",
       "3        2300.0            0.35  \n",
       "4       14800.0            0.16  \n",
       "...         ...             ...  \n",
       "2498       28.0            0.14  \n",
       "2499      108.9            1.36  \n",
       "2500      430.1            1.00  \n",
       "2501      336.9            0.68  \n",
       "2502      633.4            0.33  \n",
       "\n",
       "[2503 rows x 7 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['adv'] = df['adv'].apply(clean_str)\n",
    "df['dadv'] = df['dadv'].apply(clean_str)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "정규화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from soynlp.normalizer import *\n",
    "\n",
    "df['adv'] = [repeat_normalize(adv,num_repeats=2) for adv in df['adv']]\n",
    "df['dadv'] = [repeat_normalize(dadv,num_repeats=2) for dadv in df['dadv']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "KOBERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from konlpy.tag import Mecab\n",
    "from bertopic import BERTopic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomTokenizer:\n",
    "    def __init__(self, tagger):\n",
    "        self.tagger = tagger\n",
    "    def __call__(self, sent):\n",
    "        sent = sent[:1000000]\n",
    "        word_tokens = self.tagger.morphs(sent)\n",
    "        result = [word for word in word_tokens if len(word) > 1]\n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(tokenizer=CustomTokenizer, max_features=3000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BERTopic(embedding_model=\"sentence-transformers/xlm-r-100langs-bert-base-nli-stsb-mean-tokens\", \\\n",
    "                 vectorizer_model=vectorizer,\n",
    "                 nr_topics=50,\n",
    "                 top_n_words=10,\n",
    "                 calculate_probabilities=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91e7574382fe4839b413f54654d0c3a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)ab895/.gitattributes:   0%|          | 0.00/574 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b0ef47efd8094c3f8e0da7d2860a5a34",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)_Pooling/config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6eb846d3356341638506940f0b3ff00e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)f9e99ab895/README.md:   0%|          | 0.00/4.06k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "129b95f8d12d4cca8af275acc9a5051d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)e99ab895/config.json:   0%|          | 0.00/731 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab99130e986449f2bed795a8fec2893f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)ce_transformers.json:   0%|          | 0.00/122 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "230db153d66743fc9488ee2e3c1851a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading pytorch_model.bin:   0%|          | 0.00/1.11G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "79fe59d85abc4766843a667b3eee9ff1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)nce_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1bbe571df4f64670adc491feae166370",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)tencepiece.bpe.model:   0%|          | 0.00/5.07M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "07553ce5b0a24cb9a698f376f511d256",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)cial_tokens_map.json:   0%|          | 0.00/150 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b05f7edd9dca4afaa1344763779ecdda",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading tokenizer.json:   0%|          | 0.00/9.10M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "50339fbc9ed94b328c153c8cdd6698b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)okenizer_config.json:   0%|          | 0.00/527 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e44da03d88a74449abb48d9507ed8e86",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)99ab895/modules.json:   0%|          | 0.00/229 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "OMP: Info #276: omp_set_nested routine deprecated, please use omp_set_max_active_levels instead.\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'CustomTokenizer' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/myeongseop.kim/competition-by-AI/text_preprocessing_BERT.ipynb 셀 14\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/myeongseop.kim/competition-by-AI/text_preprocessing_BERT.ipynb#X21sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m topics, probs \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mfit_transform(df\u001b[39m.\u001b[39;49madv)\n",
      "File \u001b[0;32m~/miniconda3/envs/textmining/lib/python3.8/site-packages/bertopic/_bertopic.py:411\u001b[0m, in \u001b[0;36mBERTopic.fit_transform\u001b[0;34m(self, documents, embeddings, images, y)\u001b[0m\n\u001b[1;32m    408\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_save_representative_docs(custom_documents)\n\u001b[1;32m    409\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    410\u001b[0m      \u001b[39m# Extract topics by calculating c-TF-IDF\u001b[39;00m\n\u001b[0;32m--> 411\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_extract_topics(documents, embeddings\u001b[39m=\u001b[39;49membeddings)\n\u001b[1;32m    413\u001b[0m     \u001b[39m# Reduce topics\u001b[39;00m\n\u001b[1;32m    414\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnr_topics:\n",
      "File \u001b[0;32m~/miniconda3/envs/textmining/lib/python3.8/site-packages/bertopic/_bertopic.py:3295\u001b[0m, in \u001b[0;36mBERTopic._extract_topics\u001b[0;34m(self, documents, embeddings, mappings)\u001b[0m\n\u001b[1;32m   3286\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\" Extract topics from the clusters using a class-based TF-IDF\u001b[39;00m\n\u001b[1;32m   3287\u001b[0m \n\u001b[1;32m   3288\u001b[0m \u001b[39mArguments:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3292\u001b[0m \u001b[39m    c_tf_idf: The resulting matrix giving a value (importance score) for each word per topic\u001b[39;00m\n\u001b[1;32m   3293\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   3294\u001b[0m documents_per_topic \u001b[39m=\u001b[39m documents\u001b[39m.\u001b[39mgroupby([\u001b[39m'\u001b[39m\u001b[39mTopic\u001b[39m\u001b[39m'\u001b[39m], as_index\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\u001b[39m.\u001b[39magg({\u001b[39m'\u001b[39m\u001b[39mDocument\u001b[39m\u001b[39m'\u001b[39m: \u001b[39m'\u001b[39m\u001b[39m \u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mjoin})\n\u001b[0;32m-> 3295\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mc_tf_idf_, words \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_c_tf_idf(documents_per_topic)\n\u001b[1;32m   3296\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtopic_representations_ \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_extract_words_per_topic(words, documents)\n\u001b[1;32m   3297\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_create_topic_vectors(documents\u001b[39m=\u001b[39mdocuments, embeddings\u001b[39m=\u001b[39membeddings, mappings\u001b[39m=\u001b[39mmappings)\n",
      "File \u001b[0;32m~/miniconda3/envs/textmining/lib/python3.8/site-packages/bertopic/_bertopic.py:3488\u001b[0m, in \u001b[0;36mBERTopic._c_tf_idf\u001b[0;34m(self, documents_per_topic, fit, partial_fit)\u001b[0m\n\u001b[1;32m   3486\u001b[0m     X \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mvectorizer_model\u001b[39m.\u001b[39mpartial_fit(documents)\u001b[39m.\u001b[39mupdate_bow(documents)\n\u001b[1;32m   3487\u001b[0m \u001b[39melif\u001b[39;00m fit:\n\u001b[0;32m-> 3488\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mvectorizer_model\u001b[39m.\u001b[39;49mfit(documents)\n\u001b[1;32m   3489\u001b[0m     X \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mvectorizer_model\u001b[39m.\u001b[39mtransform(documents)\n\u001b[1;32m   3490\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/envs/textmining/lib/python3.8/site-packages/sklearn/feature_extraction/text.py:1283\u001b[0m, in \u001b[0;36mCountVectorizer.fit\u001b[0;34m(self, raw_documents, y)\u001b[0m\n\u001b[1;32m   1267\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Learn a vocabulary dictionary of all tokens in the raw documents.\u001b[39;00m\n\u001b[1;32m   1268\u001b[0m \n\u001b[1;32m   1269\u001b[0m \u001b[39mParameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1280\u001b[0m \u001b[39m    Fitted vectorizer.\u001b[39;00m\n\u001b[1;32m   1281\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   1282\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_warn_for_unused_params()\n\u001b[0;32m-> 1283\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfit_transform(raw_documents)\n\u001b[1;32m   1284\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n",
      "File \u001b[0;32m~/miniconda3/envs/textmining/lib/python3.8/site-packages/sklearn/feature_extraction/text.py:1330\u001b[0m, in \u001b[0;36mCountVectorizer.fit_transform\u001b[0;34m(self, raw_documents, y)\u001b[0m\n\u001b[1;32m   1322\u001b[0m             warnings\u001b[39m.\u001b[39mwarn(\n\u001b[1;32m   1323\u001b[0m                 \u001b[39m\"\u001b[39m\u001b[39mUpper case characters found in\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1324\u001b[0m                 \u001b[39m\"\u001b[39m\u001b[39m vocabulary while \u001b[39m\u001b[39m'\u001b[39m\u001b[39mlowercase\u001b[39m\u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1325\u001b[0m                 \u001b[39m\"\u001b[39m\u001b[39m is True. These entries will not\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1326\u001b[0m                 \u001b[39m\"\u001b[39m\u001b[39m be matched with any documents\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1327\u001b[0m             )\n\u001b[1;32m   1328\u001b[0m             \u001b[39mbreak\u001b[39;00m\n\u001b[0;32m-> 1330\u001b[0m vocabulary, X \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_count_vocab(raw_documents, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfixed_vocabulary_)\n\u001b[1;32m   1332\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbinary:\n\u001b[1;32m   1333\u001b[0m     X\u001b[39m.\u001b[39mdata\u001b[39m.\u001b[39mfill(\u001b[39m1\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/textmining/lib/python3.8/site-packages/sklearn/feature_extraction/text.py:1201\u001b[0m, in \u001b[0;36mCountVectorizer._count_vocab\u001b[0;34m(self, raw_documents, fixed_vocab)\u001b[0m\n\u001b[1;32m   1199\u001b[0m \u001b[39mfor\u001b[39;00m doc \u001b[39min\u001b[39;00m raw_documents:\n\u001b[1;32m   1200\u001b[0m     feature_counter \u001b[39m=\u001b[39m {}\n\u001b[0;32m-> 1201\u001b[0m     \u001b[39mfor\u001b[39;00m feature \u001b[39min\u001b[39;00m analyze(doc):\n\u001b[1;32m   1202\u001b[0m         \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1203\u001b[0m             feature_idx \u001b[39m=\u001b[39m vocabulary[feature]\n",
      "\u001b[0;31mTypeError\u001b[0m: 'CustomTokenizer' object is not iterable"
     ]
    }
   ],
   "source": [
    "topics, probs = model.fit_transform(df.adv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "textmining",
   "language": "python",
   "name": "textmining"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
