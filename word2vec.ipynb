{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "OlpLykQ00HPQ"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_mae(model):\n",
        "    train_pred = model.predict(x_w2v_train)\n",
        "    score = mean_absolute_error(y_train,train_pred)\n",
        "    print(model.__class__.__name__, \" train MAE: \", np.round(score,3))\n",
        "    pred = model.predict(x_w2v_test)\n",
        "    score = mean_absolute_error(y_test,pred)\n",
        "    print(model.__class__.__name__, \" MAE: \", np.round(score,3))"
      ],
      "metadata": {
        "id": "URw1Gou_-hF9"
      },
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_maes(models):\n",
        "    scores = []\n",
        "    for model in models:\n",
        "        score = get_mae(model)\n",
        "        # scores.append(score)\n",
        "    # return scores"
      ],
      "metadata": {
        "id": "t9qrDNyd-w-h"
      },
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_r2score(model):\n",
        "    train_pred = model.predict(x_w2v_train)\n",
        "    pred = model.predict(x_w2v_test)\n",
        "    train_score = r2_score(y_train,train_pred)\n",
        "    score = r2_score(y_test,pred)\n",
        "    print(model.__class__.__name__, \" train_R2SCORE: \", np.round(train_score,3))\n",
        "    print(model.__class__.__name__, \" R2SCORE: \", np.round(score,3))"
      ],
      "metadata": {
        "id": "udsAlBS8-lX8"
      },
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_r2scores(models):\n",
        "    scores = []\n",
        "    for model in models:\n",
        "        score = get_r2score(model)\n",
        "        # scores.append(score)\n",
        "    # return scores"
      ],
      "metadata": {
        "id": "o3xmLtHf_ABi"
      },
      "execution_count": 90,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_rmses(models):\n",
        "    rmses = []\n",
        "    for model in models:\n",
        "        rmse = get_rmse(model)\n",
        "        # rmses.append(rmse)\n",
        "    # return rmses"
      ],
      "metadata": {
        "id": "lirr-X6x-0hb"
      },
      "execution_count": 91,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_rmse(model):\n",
        "    train_pred = model.predict(x_w2v_train)\n",
        "    train_mse = mean_squared_error(y_train,train_pred)\n",
        "    rmse = np.sqrt(train_mse)\n",
        "    print(model.__class__.__name__, 'train RMSE: ', np.round(rmse,3))\n",
        "    pred = model.predict(x_w2v_test)\n",
        "    mse = mean_squared_error(y_test, pred)\n",
        "    rmse = np.sqrt(mse)\n",
        "    print(model.__class__.__name__, ' RMSE: ', np.round(rmse,3))\n",
        "    return rmse"
      ],
      "metadata": {
        "id": "I2M6rcu0-o9A"
      },
      "execution_count": 92,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from matplotlib import rc"
      ],
      "metadata": {
        "id": "BMgGJEEg0KBk"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def fv_preprocessing(fv):\n",
        "  fv_df = fv\n",
        "  afv = fv_df['average_salary']\n",
        "  tfv = fv_df['total_sale']\n",
        "\n",
        "  for i, val in enumerate(afv):\n",
        "    if type(val) == str:\n",
        "        if '만원' in val:\n",
        "          tmp = int(val[:-2].replace(',',''))\n",
        "          fv_df.loc[i,'average_salary'] = tmp\n",
        "        if '회사' in val:\n",
        "          fv_df.loc[i,'average_salary'] = np.NAN\n",
        "        if '수집' in val:\n",
        "          fv_df.loc[i,'average_salary'] = np.NAN\n",
        "\n",
        "  for i, val in enumerate(tfv):\n",
        "    if type(val) == str:\n",
        "        if '조원' in val:\n",
        "          tmp = float(val[:-2].replace(',',''))*1000\n",
        "          fv_df.loc[i,'total_sale'] = tmp\n",
        "        if '억원' in val:\n",
        "          tmp = float(val[:-2].replace(',',''))\n",
        "          fv_df.loc[i,'total_sale'] = tmp\n",
        "        if '억' in val:\n",
        "          tmp = float(val[:-1].replace(',',''))\n",
        "          fv_df.loc[i,'total_sale'] = tmp\n",
        "          print(fv_df.loc[i,'total_sale'])\n",
        "          print(i)\n",
        "        if '회사' in val:\n",
        "          fv_df.loc[i,'total_sale'] = np.NAN\n",
        "\n",
        "  return fv_df"
      ],
      "metadata": {
        "id": "r4hY0Nnt0dye"
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "nlp = spacy.load(\"en_core_web_sm\")"
      ],
      "metadata": {
        "id": "6eDpR8fR71cS"
      },
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터 정규화 과정 겪은 후에 contents가 길이 0인 것은 제거\n",
        "def preprocessing(review):\n",
        "    #re\n",
        "    review = re.sub(\"[^a-zA-Z]\", \" \", review)\n",
        "    word_li = review.lower().split()\n",
        "    sentence = ' '.join(word_li)\n",
        "\n",
        "    # lemmatization (spacy)\n",
        "    token_li = nlp(sentence)\n",
        "    word_li = [token.lemma_ for token in token_li if not token.is_stop]\n",
        "\n",
        "    # 문자열로 변환 (띄어쓰기 한 칸 기준으로)\n",
        "    sentence = ' '.join(word_li)\n",
        "\n",
        "    return sentence"
      ],
      "metadata": {
        "id": "jge-O0Td5IhJ"
      },
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "id": "CbFfmgkhwqhC"
      },
      "outputs": [],
      "source": [
        "combined_data = pd.read_csv(\"outlier_remove_data_tf_idf.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "error_firm = ['동원홈푸드','휠라홀딩스','트리','와디즈','키위컴퍼니','줌인터넷','시선인터내셔널','브이티코스메틱','유니슨이테크','씨엠비대전방송','서울비젼','더메인즈','조은시스템']\n",
        "for i in error_firm:\n",
        "    combined_data = combined_data[combined_data.company_name != i]\n",
        "combined_data.dropna(axis=0, inplace=True)\n",
        "combined_data = combined_data.drop(['Unnamed: 0'], axis=1)\n",
        "combined_data = fv_preprocessing(combined_data)\n",
        "tor = combined_data['turn_over_rate']\n",
        "combined_data.drop('turn_over_rate', axis=1, inplace=True)"
      ],
      "metadata": {
        "id": "Q12RYe9O0TJc"
      },
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "combined_data = combined_data.drop(['company_name'], axis = 1, inplace = False)"
      ],
      "metadata": {
        "id": "SZULv8140h0O"
      },
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "combined_data = combined_data.iloc[:, 2:]"
      ],
      "metadata": {
        "id": "G7qpiEtS0yVV"
      },
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "x_train, x_test, train_target, test_target = train_test_split(combined_data, tor, test_size=0.2)"
      ],
      "metadata": {
        "id": "nQ8hnmjK0nc3"
      },
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train['adv_dadv_combined'] = x_train['adv'] + ' ' + x_train['dadv']\n",
        "x_test['adv_dadv_combined'] = x_test['adv'] + ' ' + x_test['dadv']"
      ],
      "metadata": {
        "id": "9h5SmRJA6mXW"
      },
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re"
      ],
      "metadata": {
        "id": "CobblZgc8OQf"
      },
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Word2Vec"
      ],
      "metadata": {
        "id": "lvEo-6icJ6LD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Word2Vec은 단어로 이루어진 리스트를 입력값으로 넣어야 한다.\n",
        "x_train_li = [sentence.split() for sentence in list(x_train['adv_dadv_combined'])]\n",
        "x_test_li = [sentence.split() for sentence in list(x_test['adv_dadv_combined'])]"
      ],
      "metadata": {
        "id": "Mb59zcSn1-jc"
      },
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gensim"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KMTvBqjZ2O5-",
        "outputId": "7d39cbd9-414c-4e90-a96b-0cb6c57d99be"
      },
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gensim in /usr/local/lib/python3.10/dist-packages (4.3.2)\n",
            "Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.10/dist-packages (from gensim) (1.23.5)\n",
            "Requirement already satisfied: scipy>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from gensim) (1.11.3)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.10/dist-packages (from gensim) (6.4.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from gensim.models import word2vec\n",
        "model = word2vec.Word2Vec(x_train_li, vector_size=500, min_count=10, window=10)\n",
        "model.save(\"./w2v_model\")"
      ],
      "metadata": {
        "id": "HqbQeCHW2Qls"
      },
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def w2v_features(words, model, num_features):\n",
        "  # w2v은 단어 별 벡터의 표현이 나오기 때문에, 문장을 표현해 줄때는, 단어 별 벡터의 합을 개수로 나눠서 표현\n",
        "  # 미리 정해준 feature 차원으로 np.zeros를 만들어 준다.\n",
        "  feature_vector = np.zeros((num_features), dtype=np.float32)\n",
        "\n",
        "  count = 0\n",
        "  # 어휘사전 준비\n",
        "  index2word_set = set(model.wv.index_to_key)\n",
        "\n",
        "  for word in words:\n",
        "    if word in index2word_set:\n",
        "      count += 1\n",
        "      # 사전에 해당하는 단어에 대한 던어 벡터를 더함\n",
        "      feature_vector = np.add(feature_vector, model.wv[word])\n",
        "\n",
        "  if count == 0:\n",
        "    feature_vector = np.zeros((num_features), dtype=np.float32)\n",
        "  else:\n",
        "    feature_vector = np.divide(feature_vector, count)\n",
        "\n",
        "  return feature_vector"
      ],
      "metadata": {
        "id": "8KZWSrDq2-p4"
      },
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_features(reviews, model, num_features):\n",
        "  dataset = [w2v_features(sentence, model, num_features) for sentence in reviews]\n",
        "  review_features_vecs = np.stack(dataset)\n",
        "\n",
        "  return review_features_vecs"
      ],
      "metadata": {
        "id": "PV1LdXFo9URT"
      },
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# train\n",
        "x_w2v_train = get_features(x_train_li, model, num_features=500)\n",
        "y_train = train_target.to_numpy()\n",
        "\n",
        "# test\n",
        "x_w2v_test = get_features(x_test_li, model, num_features=500)\n",
        "y_test = test_target.to_numpy()"
      ],
      "metadata": {
        "id": "QXBnKlpy9Xgz"
      },
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_test"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZefjPYmw9tuX",
        "outputId": "6b249113-a0dd-42b6-b07d-1f33582f248b"
      },
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.45, 0.83, 0.27, 0.31, 0.15, 0.55, 0.09, 0.35, 0.39, 0.2 , 0.63,\n",
              "       0.18, 0.67, 0.14, 0.2 , 0.33, 0.31, 0.2 , 0.11, 0.34, 0.44, 0.17,\n",
              "       0.12, 0.21, 0.31, 0.26, 0.18, 0.38, 0.16, 0.17, 0.3 , 0.55, 0.23,\n",
              "       0.1 , 0.28, 0.21, 0.64, 0.51, 0.22, 0.44, 0.35, 0.23, 0.2 , 0.11,\n",
              "       0.12, 0.32, 0.09, 0.14, 0.18, 0.16, 0.22, 0.67, 0.3 , 0.18, 0.54,\n",
              "       0.08, 0.28, 0.13, 0.69, 0.33, 0.22, 0.54, 0.26, 0.39, 0.39, 0.16,\n",
              "       0.14, 0.18, 0.27, 0.58, 0.18, 0.43, 0.58, 0.1 , 0.18, 0.26, 0.22,\n",
              "       0.25, 0.82, 0.15, 0.45, 0.19, 0.75, 0.11, 0.32, 0.13, 0.21, 0.35,\n",
              "       0.21, 0.08, 0.13, 0.44, 0.25, 0.8 , 0.08, 0.79, 0.62, 0.12, 0.29,\n",
              "       0.8 , 0.23, 0.14, 0.4 , 0.54, 0.44, 0.07, 0.13, 0.14, 0.08, 0.06,\n",
              "       0.89, 0.06, 0.36, 0.3 , 0.45, 0.08, 0.21, 0.09, 0.32, 0.31, 0.38,\n",
              "       0.62, 0.39, 0.18, 0.19, 0.28, 0.13, 0.17, 0.27, 0.06, 0.24, 0.09,\n",
              "       0.07, 0.48, 0.22, 0.53, 0.18, 0.31, 0.15, 0.67, 0.15, 0.18, 0.17,\n",
              "       0.47, 0.15, 0.53, 0.08, 0.18, 0.36, 0.56, 0.12, 0.05, 0.1 , 0.19,\n",
              "       0.7 , 0.33, 0.46, 0.13, 0.52, 0.32, 0.17, 0.27, 0.11, 0.12, 0.03,\n",
              "       0.32, 0.19, 0.28, 0.12, 0.47, 0.16, 0.69, 0.13, 0.46, 0.41, 0.21,\n",
              "       0.26, 0.09, 0.57, 0.05, 0.25, 0.35, 0.16, 0.35, 0.18, 0.33, 0.5 ,\n",
              "       0.09, 0.18, 0.24, 0.46, 0.35, 0.12, 0.24, 0.2 , 0.2 , 0.23, 0.09,\n",
              "       0.4 , 0.24, 0.11, 0.19, 0.32, 0.28, 0.12, 0.74, 0.11, 0.33, 0.24,\n",
              "       0.17, 0.51, 0.22, 0.51, 0.34, 0.17, 0.2 , 0.29, 0.11, 0.3 , 0.35,\n",
              "       0.38, 0.07, 0.19, 0.33, 0.3 , 0.85, 0.14, 0.61, 0.77, 0.23, 0.21,\n",
              "       0.53, 0.02, 0.33, 0.55, 0.37, 0.54, 0.3 , 0.19, 0.46, 0.15, 0.37,\n",
              "       0.44, 0.24, 0.15, 0.12, 0.38, 0.18, 0.34, 0.28, 0.33, 0.47, 0.32,\n",
              "       0.62, 0.28, 0.27, 0.46, 0.91, 0.31, 0.27, 0.06, 0.25, 0.27, 0.29,\n",
              "       0.46, 0.24, 0.49, 0.25, 0.21, 0.86, 0.39, 0.09, 0.34, 0.04, 0.33,\n",
              "       0.15, 0.49, 0.53, 0.23, 0.34, 0.15, 0.67, 0.11, 0.29, 0.38, 0.16,\n",
              "       0.2 , 0.16, 0.23, 0.2 , 0.26, 0.22, 0.18, 0.16, 0.53, 0.55, 0.17,\n",
              "       0.25, 0.06, 0.28, 0.22, 0.44, 0.3 , 0.31, 0.11, 0.37, 0.19, 0.31,\n",
              "       0.14, 0.48, 0.08, 0.21, 0.26, 0.43, 0.38, 0.3 , 0.13, 0.44, 0.34,\n",
              "       0.28, 0.1 , 0.22, 0.13, 0.23, 0.44, 0.67, 0.54, 0.23, 0.34, 0.58,\n",
              "       0.21, 0.12, 0.82, 0.14, 0.07, 0.16, 0.66, 0.25, 0.16, 0.53, 0.34,\n",
              "       0.11, 0.43, 0.27, 0.48, 0.12, 0.18, 0.09, 0.13, 0.46, 0.44, 0.22,\n",
              "       0.3 , 0.18, 0.5 , 0.78, 0.28, 0.67, 0.06, 0.26, 0.54, 0.12, 0.21,\n",
              "       0.47, 0.16, 0.19, 0.55, 0.18, 0.19, 0.23, 0.48, 0.16, 0.33, 0.23,\n",
              "       0.28, 0.48, 0.16, 0.57, 0.48, 0.33, 0.14, 0.13, 0.4 , 0.1 , 0.11,\n",
              "       0.1 , 0.47, 0.2 , 0.13, 0.27, 0.16, 0.2 , 0.19, 0.71, 0.07, 0.14,\n",
              "       0.25, 0.35, 0.19, 0.15, 0.43, 0.12, 0.19, 0.17, 0.19, 0.06, 0.34,\n",
              "       0.4 , 0.4 , 0.24, 0.28, 0.31, 0.29, 0.14, 0.89, 0.54, 0.13, 0.15,\n",
              "       0.16, 0.35, 0.57, 0.55, 0.71, 0.15, 0.22, 0.07, 0.64, 0.23, 0.42,\n",
              "       0.78, 0.09, 0.3 , 0.09, 0.2 , 0.11, 0.34, 0.14, 0.27, 0.26, 0.16,\n",
              "       0.33, 0.25, 0.25, 0.22, 0.18, 0.11, 0.75, 0.24, 0.14, 0.68, 0.15,\n",
              "       0.46, 0.43, 0.11, 0.15])"
            ]
          },
          "metadata": {},
          "execution_count": 85
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Linear Regression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
        "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
        "\n",
        "\n",
        "lr_reg = LinearRegression()\n",
        "lr_reg.fit(x_w2v_train, y_train)\n",
        "\n",
        "ridge_reg = Ridge()\n",
        "ridge_reg.fit(x_w2v_train, y_train)\n",
        "\n",
        "lasso_reg = Lasso()\n",
        "lasso_reg.fit(x_w2v_train,y_train)\n",
        "\n",
        "models = [lr_reg, ridge_reg, lasso_reg]\n",
        "get_rmses(models)\n",
        "print('\\n')\n",
        "get_r2scores(models)\n",
        "print('\\n')\n",
        "get_maes(models)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fq_xkRnl9bV5",
        "outputId": "6f224122-93bc-482c-92e1-df4c6e47ee22"
      },
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LinearRegression train RMSE:  0.125\n",
            "LinearRegression  RMSE:  0.177\n",
            "Ridge train RMSE:  0.149\n",
            "Ridge  RMSE:  0.162\n",
            "Lasso train RMSE:  0.187\n",
            "Lasso  RMSE:  0.186\n",
            "\n",
            "\n",
            "LinearRegression  train_R2SCORE:  0.555\n",
            "LinearRegression  R2SCORE:  0.091\n",
            "Ridge  train_R2SCORE:  0.367\n",
            "Ridge  R2SCORE:  0.234\n",
            "Lasso  train_R2SCORE:  -0.0\n",
            "Lasso  R2SCORE:  -0.003\n",
            "\n",
            "\n",
            "LinearRegression  train MAE:  0.094\n",
            "LinearRegression  MAE:  0.131\n",
            "Ridge  train MAE:  0.112\n",
            "Ridge  MAE:  0.121\n",
            "Lasso  train MAE:  0.148\n",
            "Lasso  MAE:  0.149\n"
          ]
        }
      ]
    }
  ]
}