{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Data\n",
    "df = pd.read_csv(\"tp_df.csv\")\n",
    "df = df.drop([\"Unnamed: 0\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop Errors and NAN values\n",
    "df = df[df['turn_over_rate']<1]\n",
    "error_firm = ['동원홈푸드','휠라홀딩스','트리','와디즈','키위컴퍼니','줌인터넷','시선인터내셔널','브이티코스메틱','유니슨이테크','씨엠비대전방송','서울비젼','더메인즈','조은시스템']\n",
    "\n",
    "for i in error_firm:\n",
    "    df = df[df.company_name != i]\n",
    "\n",
    "# Rename the columns\n",
    "df = df.rename(columns={\"average_salary\":\"average_salary(만원)\", \"total_sale\":\"total_sale(억원)\"})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from matplotlib import rc\n",
    "\n",
    "# for Mac\n",
    "rc('font', family='AppleGothic')\n",
    "\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "\n",
    "# Get turn_over_rate graphs\n",
    "\n",
    "plt.title('turn_over_rate')\n",
    "plt.xticks(rotation = 45)\n",
    "sns.histplot(df['turn_over_rate'],kde=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adv_list = df.columns[1:7]\n",
    "adv_col = 3\n",
    "dadv_list = df.columns[7:-3]\n",
    "dadv_col = 4\n",
    "fv_list = df.columns[-3:-1]\n",
    "fv_col = 1\n",
    "\n",
    "def graphing_data (col, num):\n",
    "    plt.figure(figsize=(24,12))\n",
    "    for i, title in enumerate(col):\n",
    "        plt.subplot(2,num,i+1)\n",
    "        plt.title(title+\" scatter plot\")\n",
    "        sns.scatterplot(x= df[title].astype(float), y = df['turn_over_rate'])\n",
    "\n",
    "    # if col[0][-1].isdigit():\n",
    "    #     if col[0][0] == 'a':\n",
    "    #         plt.savefig('Advatage_topic_modeling_scatter_plot.png')\n",
    "    #     if col[0][0] == 'd':\n",
    "    #         plt.savefig('Disadvatage_topic_modeling_scatter_plot.png')\n",
    "    # else:\n",
    "    #     plt.savefig('Financial_variable_scatter_plot.png')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graphing_data(adv_list, adv_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graphing_data(dadv_list,dadv_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graphing_data(fv_list,fv_col)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Machine Learning**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Linear, Ridge, Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rmse(model):\n",
    "    pred = model.predict(X_test.astype(float))\n",
    "    mse = mean_squared_error(y_test.astype(float), pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "    print(model.__class__.__name__, ' RMSE: ', np.round(rmse,3))\n",
    "    return rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mae(model):\n",
    "    pred = model.predict(X_test.astype(float))\n",
    "    score = mean_absolute_error(y_test.astype(float),pred)\n",
    "    print(model.__class__.__name__, \" MAE: \", np.round(score,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rmses(models):\n",
    "    rmses = []\n",
    "    for model in models:\n",
    "        rmse = get_rmse(model)\n",
    "        # rmses.append(rmse)\n",
    "    # return rmses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_maes(models):\n",
    "    scores = []\n",
    "    for model in models:\n",
    "        score = get_mae(model)\n",
    "        # scores.append(score)\n",
    "    # return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linear Regression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "\n",
    "y_target = df['turn_over_rate']\n",
    "x_data = df.drop(['company_name','turn_over_rate'], axis = 1, inplace = False)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(x_data, y_target, test_size = 0.1, random_state = 7)\n",
    "\n",
    "lr_reg = LinearRegression()\n",
    "lr_reg.fit(X_train, y_train)\n",
    "\n",
    "ridge_reg = Ridge()\n",
    "ridge_reg.fit(X_train, y_train)\n",
    "\n",
    "lasso_reg = Lasso()\n",
    "lasso_reg.fit(X_train,y_train)\n",
    "\n",
    "models = [lr_reg, ridge_reg, lasso_reg]\n",
    "get_rmses(models)\n",
    "print('\\n')\n",
    "get_maes(models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_bottom_coef(model, n=4):\n",
    "\n",
    "    coef = pd.Series(model.coef_, index=x_data.columns)\n",
    "\n",
    "    coef_high = coef.sort_values(ascending=False).head(n)\n",
    "    coef_low = coef.sort_values(ascending=False).tail(n)\n",
    "\n",
    "    return coef_high, coef_low"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_coefficient(models):\n",
    "    fig, axs = plt.subplots(figsize = (24,10), nrows = 1, ncols= 3)\n",
    "    fig.tight_layout()\n",
    "\n",
    "    for i_num, model in enumerate(models):\n",
    "\n",
    "        coef_high, coef_low = get_top_bottom_coef(model)\n",
    "        coef_concat = pd.concat([coef_high, coef_low])\n",
    "\n",
    "        axs[i_num].set_title(model.__class__.__name__+' Coefficients', size=25)\n",
    "        axs[i_num].tick_params(axis=\"y\", direction=\"in\",pad=-120)\n",
    "        for label in (axs[i_num].get_xticklabels() + axs[i_num].get_yticklabels()):\n",
    "            label.set_fontsize(22)\n",
    "        sns.barplot(x=coef_concat.values, y=coef_concat.index, ax = axs[i_num])\n",
    "\n",
    "models = [lr_reg, ridge_reg, lasso_reg]\n",
    "visualize_coefficient(models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "def get_avg_rmse_cv(models):\n",
    "\n",
    "    for model in models:\n",
    "\n",
    "        rmse_list = np.sqrt(-cross_val_score(model, x_data, y_target,\n",
    "                                             scoring= 'neg_mean_squared_error', cv = 5))\n",
    "        rmse_avg = np.mean(rmse_list)\n",
    "        print('\\n{0} CV RMSE Value List: {1}'.format(model.__class__.__name__, np.round(rmse_list,3)))\n",
    "        print('\\n{0} CV average RMSE Value List: {1}'.format(model.__class__.__name__, np.round(rmse_avg,3)))\n",
    "\n",
    "models = [ridge_reg, lasso_reg]\n",
    "get_avg_rmse_cv(models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "def print_best_params(model, params):\n",
    "\n",
    "    grid_model = GridSearchCV(model, param_grid=params,\n",
    "                              scoring='neg_mean_squared_error', cv=5)\n",
    "    grid_model.fit(X_train.astype(float),y_train.astype(float))\n",
    "    mse = -1 * grid_model.best_score_\n",
    "    rmse = np.sqrt(-1*grid_model.best_score_)\n",
    "    print('{0} After 5 CV, best average MSE: {1}, best average RMSE: {2}, best alpha: {3}'.format(model.__class__.__name__,np.round(mse,4),\n",
    "                                                                           np.round(rmse,4),grid_model.best_params_))\n",
    "    print('\\n')     \n",
    "\n",
    "\n",
    "def save_best_params(model, params):\n",
    "\n",
    "    grid_model = GridSearchCV(model, param_grid=params,\n",
    "                              scoring='neg_mean_squared_error', cv=5)\n",
    "    grid_model.fit(X_train.astype(float),y_train.astype(float))\n",
    "    mse = -1 * grid_model.best_score_\n",
    "    rmse = np.sqrt(-1*grid_model.best_score_)\n",
    "    print('{0} After 5 CV, best average MSE: {1}, best average RMSE: {2}, best alpha: {3}'.format(model.__class__.__name__,np.round(mse,4),\n",
    "                                                                           np.round(rmse,4),grid_model.best_params_))\n",
    "    print('\\n')     \n",
    "\n",
    "    return grid_model.best_params_\n",
    "\n",
    "    \n",
    "\n",
    "ridge_params = {'alpha':[0.05, 0.1, 1, 5, 8, 10, 12, 15, 20]}\n",
    "lasso_params = {'alpha':[0.001, 0.005, 0.008, 0.05, 0.03, 0.1, 0.5, 1, 5, 10]}\n",
    "print_best_params(ridge_reg,ridge_params)\n",
    "print_best_params(lasso_reg,lasso_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_reg = LinearRegression()\n",
    "lr_reg.fit(X_train, y_train)\n",
    "\n",
    "ridge_reg = Ridge(alpha=20)\n",
    "ridge_reg.fit(X_train, y_train)\n",
    "\n",
    "lasso_reg = Lasso(alpha=0.001)\n",
    "lasso_reg.fit(X_train,y_train)\n",
    "\n",
    "models = [lr_reg, ridge_reg, lasso_reg]\n",
    "get_rmses(models)\n",
    "\n",
    "visualize_coefficient(models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding Skewed Feature\n",
    "from scipy.stats import skew\n",
    "\n",
    "feature_index = df.dtypes[df.dtypes != 'object'].index\n",
    "\n",
    "skew_features = df[feature_index].apply(lambda x: skew(x))\n",
    "\n",
    "skew_feature_top = skew_features[skew_features > 1]\n",
    "print(skew_feature_top.sort_values(ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# log transformation for skewed values\n",
    "for feature in skew_feature_top.index:\n",
    "    nonzero_indices = df[feature] != 0  # 0이 아닌 값의 인덱스를 찾음\n",
    "    addup = min(df[nonzero_indices][feature])\n",
    "    df[feature] = np.log1p(df[feature]+addup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_target = df['turn_over_rate']\n",
    "x_data = df.drop(['company_name','turn_over_rate'], axis = 1, inplace = False)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(x_data, y_target, test_size = 0.1, random_state = 7)\n",
    "\n",
    "ridge_params = {'alpha':[0.05, 0.1, 1, 5, 8, 10, 12, 15, 20]}\n",
    "lasso_params = {'alpha':[0.001, 0.005, 0.008, 0.05, 0.03, 0.1, 0.5, 1, 5, 10]}\n",
    "print_best_params(ridge_reg,ridge_params)\n",
    "print_best_params(lasso_reg,lasso_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_reg = LinearRegression()\n",
    "lr_reg.fit(X_train, y_train)\n",
    "\n",
    "ridge_reg = Ridge(alpha=0.05)\n",
    "ridge_reg.fit(X_train, y_train)\n",
    "\n",
    "lasso_reg = Lasso(alpha=0.001)\n",
    "lasso_reg.fit(X_train,y_train)\n",
    "\n",
    "models = [lr_reg, ridge_reg, lasso_reg]\n",
    "get_rmses(models)\n",
    "print('\\n')\n",
    "get_maes(models)\n",
    "\n",
    "visualize_coefficient(models)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decision Tree with Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "xgbooost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBRegressor \n",
    "\n",
    "xgb_params = {'n_estimators': [500, 750, 1000], \n",
    "              'learning_rate': [0.05, 0.1, 0.15, 0.2], \n",
    "              'max_depth' : [4,6,8,10]}\n",
    "xgb_reg = XGBRegressor(n_estimators = 1000, learning_rate = 0.05, colsample_bytree = 0.5, subsample = 0.8)\n",
    "\n",
    "xgb_best_params = save_best_params(xgb_reg, xgb_params)\n",
    "\n",
    "print(xgb_best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# work after best params\n",
    "xgb_reg = XGBRegressor(n_estimators = 500, learning_rate = 0.05, max_depth = 4, colsample_bytree = 0.5, subsample = 0.8)\n",
    "xgb_reg.fit(X_train.astype(float),y_train.astype(float))\n",
    "\n",
    "get_mae(xgb_reg)\n",
    "get_rmse(xgb_reg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "light gbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightgbm import LGBMRegressor\n",
    "\n",
    "lgbm_params = {'n_estimators': [500, 750, 1000], \n",
    "              'learning_rate': [0.05, 0.1, 0.15, 0.2], \n",
    "              'num_leaves' : [4, 6, 8, 10]}\n",
    "lgbm_reg = LGBMRegressor(n_estimators=1000, learning_rate= 0.05, num_leaves=4,\n",
    "                         subsample=0.6, colsample_bytree=0.4, reg_lambda=10, n_jobs=-1)\n",
    "lgbm_best_params = save_best_params(lgbm_reg,lgbm_params)\n",
    "\n",
    "print(lgbm_best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# work after best params\n",
    "lgbm_reg = LGBMRegressor(n_estimators=500, learning_rate= 0.05, num_leaves=4,\n",
    "                         subsample=0.6, colsample_bytree=0.4, reg_lambda=10, n_jobs=-1)\n",
    "lgbm_reg.fit(X_train.astype(float),y_train.astype(float))\n",
    "\n",
    "get_mae(lgbm_reg)\n",
    "get_rmse(lgbm_reg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "gradient boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "gb_params = {'n_estimators': [500, 750, 1000], \n",
    "              'learning_rate': [0.05, 0.1, 0.15, 0.2], \n",
    "              'max_depth' : [4,6,8,10]}\n",
    "gb_reg = GradientBoostingRegressor(n_estimators=1000, learning_rate= 0.05, subsample=0.6 )\n",
    "gb_best_params = save_best_params(gb_reg,gb_params)\n",
    "\n",
    "print(gb_best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# work after best params\n",
    "gb_reg = GradientBoostingRegressor(n_estimators=750, learning_rate= 0.05, subsample=0.6, max_depth=10 )\n",
    "gb_reg.fit(X_train.astype(float),y_train.astype(float))\n",
    "\n",
    "get_mae(gb_reg)\n",
    "get_rmse(gb_reg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "rf_params = {'n_estimators': [500, 750, 1000],\n",
    "             'max_depth' : [4,6,8,10]}\n",
    "rf_reg = RandomForestRegressor(n_estimators=1000)\n",
    "rf_best_params = save_best_params(rf_reg,rf_params)\n",
    "\n",
    "print(rf_best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# work after best params\n",
    "\n",
    "rf_reg = RandomForestRegressor(n_estimators=500)\n",
    "rf_reg.fit(X_train,y_train)\n",
    "\n",
    "get_mae(rf_reg)\n",
    "get_rmse(rf_reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "dt_params = {'max_depth' : [4,6,8,10]}\n",
    "dt_reg = DecisionTreeRegressor(max_depth=4)\n",
    "dt_best_params = save_best_params(dt_reg, dt_params)\n",
    "\n",
    "print(dt_best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# work after best params\n",
    "\n",
    "dt_reg = DecisionTreeRegressor(max_depth=4)\n",
    "dt_reg.fit(X_train,y_train)\n",
    "\n",
    "get_mae(dt_reg)\n",
    "get_rmse(dt_reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature graph xgb\n",
    "xgb_reg.fit(x_data.astype(float), y_target.astype(float))\n",
    "\n",
    "feature_series = pd.Series(data = xgb_reg.feature_importances_, index =x_data.columns)\n",
    "feature_series = feature_series.sort_values(ascending=False)\n",
    "sns.barplot(x=feature_series, y= feature_series.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Graph lgbm\n",
    "lgbm_reg.fit(x_data.astype('float'), y_target.astype('float'))\n",
    "\n",
    "feature_series = pd.Series(data = lgbm_reg.feature_importances_, index =x_data.columns)\n",
    "feature_series = feature_series.sort_values(ascending=False)\n",
    "sns.barplot(x=feature_series, y= feature_series.index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature graph gradient boosting\n",
    "\n",
    "gb_reg.fit(x_data.astype('float'), y_target.astype('float'))\n",
    "\n",
    "feature_series = pd.Series(data = gb_reg.feature_importances_, index =x_data.columns)\n",
    "feature_series = feature_series.sort_values(ascending=False)\n",
    "sns.barplot(x=feature_series, y= feature_series.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature graph randomforest\n",
    "\n",
    "rf_reg.fit(x_data.astype('float'), y_target.astype('float'))\n",
    "\n",
    "feature_series = pd.Series(data = rf_reg.feature_importances_, index =x_data.columns)\n",
    "feature_series = feature_series.sort_values(ascending=False)\n",
    "sns.barplot(x=feature_series, y= feature_series.index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Graph DecisionTree\n",
    "dt_reg.fit(x_data.astype('float'), y_target.astype('float'))\n",
    "\n",
    "feature_series = pd.Series(data = dt_reg.feature_importances_, index =x_data.columns)\n",
    "feature_series = feature_series.sort_values(ascending=False)\n",
    "sns.barplot(x=feature_series, y= feature_series.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Export Trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import joblib\n",
    "\n",
    "# joblib.dump(lgbm_reg,\"tp_lgbm_reg_model.pkl\")\n",
    "joblib.dump(xgb_reg,\"tp_xgb_reg_model.pkl\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "textmining",
   "language": "python",
   "name": "textmining"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
